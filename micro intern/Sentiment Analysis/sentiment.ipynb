{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109b16df-cc38-400b-bc5b-387101e0a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f78c0660-0f0a-44fd-9a08-1a8172a43d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\rohit\\Downloads\\micro intern\\archive (5).zip\")  # Change the filename if needed\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Check available columns\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6972ec-66ee-48ca-bf7d-52117b285f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   Score   568454 non-null  int64 \n",
      " 1   Text    568454 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Keep only 'Score' and 'Text' columns\n",
    "df = df[['Score', 'Text']]\n",
    "\n",
    "# Remove missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Show dataset info\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b622837f-3e58-4aa3-9eef-bfe0b63053e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "Positive    443777\n",
      "Negative     82037\n",
      "Neutral      42640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def convert_score_to_sentiment(score):\n",
    "    if score >= 4:\n",
    "        return \"Positive\"\n",
    "    elif score == 3:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Negative\"\n",
    "\n",
    "# Apply conversion\n",
    "df[\"Sentiment\"] = df[\"Score\"].apply(convert_score_to_sentiment)\n",
    "\n",
    "# Remove original 'Score' column\n",
    "df = df.drop(columns=[\"Score\"])\n",
    "\n",
    "# Show sentiment distribution\n",
    "print(df[\"Sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cea9aac3-3440-4030-ad20-23233d1c173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rohit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary data for text processing\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43dc269a-1b1d-4108-bb20-ab5f1bda093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  I have bought several of the Vitality canned d...   \n",
      "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
      "2  This is a confection that has been around a fe...   \n",
      "3  If you are looking for the secret ingredient i...   \n",
      "4  Great taffy at a great price.  There was a wid...   \n",
      "\n",
      "                                        Cleaned_Text Sentiment  \n",
      "0  bought several vitality canned dog food produc...  Positive  \n",
      "1  product arrived labeled jumbo salted peanut pe...  Negative  \n",
      "2  confection around century light pillowy citrus...  Positive  \n",
      "3  looking secret ingredient robitussin believe f...  Negative  \n",
      "4  great taffy great price wide assortment yummy ...  Positive  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
    "    tokens = word_tokenize(text)  # Tokenization\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]  # Stopword removal & lemmatization\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply text cleaning\n",
    "df[\"Cleaned_Text\"] = df[\"Text\"].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Show cleaned text samples\n",
    "print(df[[\"Text\", \"Cleaned_Text\", \"Sentiment\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4798df67-f3e0-4bf7-8880-fff8b1923eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Preprocessing Complete! Cleaned dataset saved as 'Cleaned_Reviews.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"Cleaned_Reviews.csv\", index=False)\n",
    "print(\"\\n✅ Preprocessing Complete! Cleaned dataset saved as 'Cleaned_Reviews.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c880ecb-b67a-4b48-9749-a44c353d97b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4209aaa-cd1d-4c61-ad90-ed5cecbf0202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text Sentiment  \\\n",
      "0  I have bought several of the Vitality canned d...  Positive   \n",
      "1  Product arrived labeled as Jumbo Salted Peanut...  Negative   \n",
      "2  This is a confection that has been around a fe...  Positive   \n",
      "3  If you are looking for the secret ingredient i...  Negative   \n",
      "4  Great taffy at a great price.  There was a wid...  Positive   \n",
      "\n",
      "                                        Cleaned_Text  \n",
      "0  bought several vitality canned dog food produc...  \n",
      "1  product arrived labeled jumbo salted peanut pe...  \n",
      "2  confection around century light pillowy citrus...  \n",
      "3  looking secret ingredient robitussin believe f...  \n",
      "4  great taffy great price wide assortment yummy ...  \n",
      "Sentiment\n",
      "Positive    443777\n",
      "Negative     82037\n",
      "Neutral      42640\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv(\"Cleaned_Reviews.csv\")\n",
    "\n",
    "# Show first 5 rows\n",
    "print(df.head())\n",
    "\n",
    "# Check data distribution\n",
    "print(df[\"Sentiment\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f27547ed-031d-40f2-b33c-c1d25a407958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix Shape: (568454, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Use 5000 most important words\n",
    "X = vectorizer.fit_transform(df[\"Cleaned_Text\"])\n",
    "\n",
    "# Convert labels to numerical values (0 = Negative, 1 = Neutral, 2 = Positive)\n",
    "sentiment_mapping = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "y = df[\"Sentiment\"].map(sentiment_mapping)\n",
    "\n",
    "# Show the shape of the transformed data\n",
    "print(\"Feature Matrix Shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd1ccd15-c842-4f25-ac93-21476617d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 454763\n",
      "Testing Set Size: 113691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Show dataset sizes\n",
    "print(\"Training Set Size:\", X_train.shape[0])\n",
    "print(\"Testing Set Size:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76d5385f-cd62-4df6-906a-78e6e5cdf96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a69c88c-cc37-4d68-b2be-acdda6fbf5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8664186259246555\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70     16181\n",
      "           1       0.51      0.17      0.26      8485\n",
      "           2       0.90      0.97      0.93     89025\n",
      "\n",
      "    accuracy                           0.87    113691\n",
      "   macro avg       0.71      0.60      0.63    113691\n",
      "weighted avg       0.85      0.87      0.85    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "# Show detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38390932-7a36-486b-99e9-149d3b811dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: This product is amazing! I love it. → Sentiment: Positive\n",
      "Review: It's okay, not the best but not the worst. → Sentiment: Negative\n",
      "Review: Horrible experience, I would never buy this again! → Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Define custom reviews\n",
    "custom_reviews = [\n",
    "    \"This product is amazing! I love it.\",\n",
    "    \"It's okay, not the best but not the worst.\",\n",
    "    \"Horrible experience, I would never buy this again!\"\n",
    "]\n",
    "\n",
    "# Convert text to TF-IDF features\n",
    "custom_vectors = vectorizer.transform(custom_reviews)\n",
    "\n",
    "# Predict sentiment\n",
    "predictions = model.predict(custom_vectors)\n",
    "\n",
    "# Convert back to text labels\n",
    "label_mapping = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "predicted_sentiments = [label_mapping[p] for p in predictions]\n",
    "\n",
    "# Display results\n",
    "for review, sentiment in zip(custom_reviews, predicted_sentiments):\n",
    "    print(f\"Review: {review} → Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67ffe23c-53f7-4a48-9ecb-aa2d915c7fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bddc417-8eb3-49c3-8747-5afa4c8f0900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model and Vectorizer Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, \"sentiment_model.pkl\")\n",
    "\n",
    "# Save the TF-IDF vectorizer \n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"\\n✅ Model and Vectorizer Saved Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef416faa-61fd-4bbf-9794-8dc19fdcb024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
